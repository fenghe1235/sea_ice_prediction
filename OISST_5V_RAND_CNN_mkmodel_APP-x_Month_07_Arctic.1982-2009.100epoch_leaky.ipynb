{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_fy    = 'APP-x.1400.ERA-I.1982-2018.07.Arctic.1982-2009.nc'\n",
    "nc_fm    = 'APP-x.1400.ERA-I.1982-2018.06.Arctic.1982-2009.nc'\n",
    "nc_fay   = 'APP-x.1400.ERA-I.1982-2018.07.anom.wrt.2001-2018.Arctic.1982-2009.nc'\n",
    "nc_fam   = 'APP-x.1400.ERA-I.1982-2018.06.anom.wrt.2001-2018.Arctic.1982-2009.nc'\n",
    "h5_model = 'APP-x.1400.ERA-I.1982-2018.07.Arctic.1982-2009.5V.RAND.100epoch_leaky.h5'\n",
    "pg_train = 'APP-x.1400.ERA-I.1982-2018.07.training.Arctic.1982-2009.5V.RAND.100epoch_leaky.png'\n",
    "pg_predt = 'APP-x.1400.ERA-I.1982-2018.07.prediction.Arctic.1982-2009.5V.RAND.100epoch_leaky.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting CNN Model\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "psize  = 11\n",
    "ptrain = 0.90\n",
    "cx     = int((psize-1)/2)\n",
    "cy     = int((psize-1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file for SIC Yr-1\n",
    "\n",
    "nc_fidy  = Dataset(nc_fy, 'r')\n",
    "time    = nc_fidy.variables['time'][:]\n",
    "\n",
    "ysic0   = nc_fidy.variables['icecon'][:]\n",
    "ythk0   = nc_fidy.variables['t2m'][:]\n",
    "yvtn0   = nc_fidy.variables['v10'][:]\n",
    "ytem0   = nc_fidy.variables['sst'][:]\n",
    "yalb0   = nc_fidy.variables['fal'][:]\n",
    "\n",
    "# input file for SIC, THK, Temperature and ALBEDO Mon-1\n",
    "\n",
    "nc_fidm = Dataset(nc_fm, 'r')\n",
    "msic0   = nc_fidm.variables['icecon'][:]\n",
    "mthk0   = nc_fidm.variables['t2m'][:]\n",
    "mvtn0   = nc_fidm.variables['v10'][:]\n",
    "mtem0   = nc_fidm.variables['sst'][:]\n",
    "malb0   = nc_fidm.variables['fal'][:]\n",
    "\n",
    "# input file for SIC Anomaly, Yr-1\n",
    "\n",
    "nc_fiday = Dataset(nc_fay, 'r')\n",
    "aysic0   = nc_fiday.variables['icecon'][:]\n",
    "aythk0   = nc_fiday.variables['t2m'][:]\n",
    "ayvtn0   = nc_fiday.variables['v10'][:]\n",
    "aytem0   = nc_fiday.variables['sst'][:]\n",
    "ayalb0   = nc_fiday.variables['fal'][:]\n",
    "\n",
    "# input file for SIC Anomaly, Mon-1\n",
    "\n",
    "nc_fidam = Dataset(nc_fam, 'r')\n",
    "amsic0   = nc_fidam.variables['icecon'][:]\n",
    "amthk0   = nc_fidam.variables['t2m'][:]\n",
    "amvtn0   = nc_fidam.variables['v10'][:]\n",
    "amtem0   = nc_fidam.variables['sst'][:]\n",
    "amalb0   = nc_fidam.variables['fal'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysic1   = np.transpose(ysic0)\n",
    "ythk1   = np.transpose(ythk0)\n",
    "yvtn1   = np.transpose(yvtn0)\n",
    "ytem1   = np.transpose(ytem0)\n",
    "yalb1   = np.transpose(yalb0)\n",
    "\n",
    "msic1   = np.transpose(msic0)\n",
    "mthk1   = np.transpose(mthk0)\n",
    "mvtn1   = np.transpose(mvtn0)\n",
    "mtem1   = np.transpose(mtem0)\n",
    "malb1   = np.transpose(malb0)\n",
    "\n",
    "aysic1   = np.transpose(aysic0)\n",
    "aythk1   = np.transpose(aythk0)\n",
    "ayvtn1   = np.transpose(ayvtn0)\n",
    "aytem1   = np.transpose(aytem0)\n",
    "ayalb1   = np.transpose(ayalb0)\n",
    "\n",
    "amsic1   = np.transpose(amsic0)\n",
    "amthk1   = np.transpose(amthk0)\n",
    "amvtn1   = np.transpose(amvtn0)\n",
    "amtem1   = np.transpose(amtem0)\n",
    "amalb1   = np.transpose(amalb0)\n",
    "\n",
    "\n",
    "print(\"msic1.shape:\", msic1.shape)\n",
    "print(\"ysic1.shape:\", ysic1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs\n",
    "\n",
    "Y_SIC2   = np.nan_to_num(ysic1[:,:,1:])\n",
    "Y_time   = time[1:]\n",
    "\n",
    "ysic2    = np.nan_to_num(ysic1[:,:,:-1])\n",
    "ythk2    = np.nan_to_num(ythk1[:,:,:-1])\n",
    "yvtn2    = np.nan_to_num(yvtn1[:,:,:-1])\n",
    "ytem2    = np.nan_to_num(ytem1[:,:,:-1])\n",
    "yalb2    = np.nan_to_num(yalb1[:,:,:-1])\n",
    "\n",
    "\n",
    "msic2    = np.nan_to_num(msic1[:,:,1:])\n",
    "mthk2    = np.nan_to_num(mthk1[:,:,1:])\n",
    "mvtn2    = np.nan_to_num(mvtn1[:,:,1:])\n",
    "mtem2    = np.nan_to_num(mtem1[:,:,1:])\n",
    "malb2    = np.nan_to_num(malb1[:,:,1:])\n",
    "\n",
    "aysic2    = np.nan_to_num(aysic1[:,:,:-1])\n",
    "aythk2    = np.nan_to_num(aythk1[:,:,:-1])\n",
    "ayvtn2    = np.nan_to_num(ayvtn1[:,:,:-1])\n",
    "aytem2    = np.nan_to_num(aytem1[:,:,:-1])\n",
    "ayalb2    = np.nan_to_num(ayalb1[:,:,:-1])\n",
    "\n",
    "amsic2    = np.nan_to_num(amsic1[:,:,1:])\n",
    "amthk2    = np.nan_to_num(amthk1[:,:,1:])\n",
    "amvtn2    = np.nan_to_num(amvtn1[:,:,1:])\n",
    "amtem2    = np.nan_to_num(amtem1[:,:,1:])\n",
    "amalb2    = np.nan_to_num(amalb1[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input data of SIC Yr-1: ', ysic2.shape)\n",
    "print(ysic2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of SIC MON-1: ', msic2.shape)\n",
    "print(msic2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of Anomaly SIC Yr-1: ', aysic2.shape)\n",
    "print(aysic2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of Anomaly SIC Mon-1: ', amsic2.shape)\n",
    "print(amsic2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of THK Mon-1: ', mthk2.shape)\n",
    "print(mthk2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of V10 Mon-1: ', mvtn2.shape)\n",
    "print(mvtn2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of TEMP Mon-1: ', mtem2.shape)\n",
    "print(mtem2[:,:,0])\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('input data of ALBEDO Mon-1: ', malb2.shape)\n",
    "print(malb2[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SIC3 = image.extract_patches_2d(Y_SIC2, (psize, psize))\n",
    "\n",
    "ysic3  = image.extract_patches_2d(ysic2,  (psize, psize))\n",
    "ythk3  = image.extract_patches_2d(ythk2,  (psize, psize))\n",
    "yvtn3  = image.extract_patches_2d(yvtn2,  (psize, psize))\n",
    "ytem3  = image.extract_patches_2d(ytem2,  (psize, psize))\n",
    "yalb3  = image.extract_patches_2d(yalb2,  (psize, psize))\n",
    "\n",
    "msic3  = image.extract_patches_2d(msic2,  (psize, psize))\n",
    "mthk3  = image.extract_patches_2d(mthk2,  (psize, psize))\n",
    "mvtn3  = image.extract_patches_2d(mvtn2,  (psize, psize))\n",
    "mtem3  = image.extract_patches_2d(mtem2,  (psize, psize))\n",
    "malb3  = image.extract_patches_2d(malb2,  (psize, psize))\n",
    "\n",
    "amsic3 = image.extract_patches_2d(amsic2, (psize, psize))\n",
    "amthk3 = image.extract_patches_2d(amthk2, (psize, psize))\n",
    "amvtn3 = image.extract_patches_2d(amvtn2, (psize, psize))\n",
    "amtem3 = image.extract_patches_2d(amtem2, (psize, psize))\n",
    "amalb3 = image.extract_patches_2d(amalb2, (psize, psize))\n",
    "\n",
    "aysic3 = image.extract_patches_2d(aysic2, (psize, psize))\n",
    "aythk3 = image.extract_patches_2d(aythk2, (psize, psize))\n",
    "ayvtn3 = image.extract_patches_2d(ayvtn2, (psize, psize))\n",
    "aytem3 = image.extract_patches_2d(aytem2, (psize, psize))\n",
    "ayalb3 = image.extract_patches_2d(ayalb2, (psize, psize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ysic3 shape:\", ysic3.shape)\n",
    "print(\" msic3 shape:\", msic3.shape)\n",
    "print(\"aysic3 shape:\", aysic3.shape)\n",
    "print(\"amsic3 shape:\", amsic3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SIC  = np.transpose(Y_SIC3,(1,2,3,0))\n",
    "\n",
    "ysic   = np.transpose(ysic3,(1,2,3,0))\n",
    "ythk   = np.transpose(ythk3,(1,2,3,0))\n",
    "yvtn   = np.transpose(yvtn3,(1,2,3,0))\n",
    "ytem   = np.transpose(ytem3,(1,2,3,0))\n",
    "yalb   = np.transpose(yalb3,(1,2,3,0))\n",
    "\n",
    "msic   = np.transpose(msic3,(1,2,3,0))\n",
    "mthk   = np.transpose(mthk3,(1,2,3,0))\n",
    "mvtn   = np.transpose(mvtn3,(1,2,3,0))\n",
    "mtem   = np.transpose(mtem3,(1,2,3,0))\n",
    "malb   = np.transpose(malb3,(1,2,3,0))\n",
    "\n",
    "aysic   = np.transpose(aysic3,(1,2,3,0))\n",
    "aythk   = np.transpose(aythk3,(1,2,3,0))\n",
    "ayvtn   = np.transpose(ayvtn3,(1,2,3,0))\n",
    "aytem   = np.transpose(aytem3,(1,2,3,0))\n",
    "ayalb   = np.transpose(ayalb3,(1,2,3,0))\n",
    "\n",
    "amsic   = np.transpose(amsic3,(1,2,3,0))\n",
    "amthk   = np.transpose(amthk3,(1,2,3,0))\n",
    "amvtn   = np.transpose(amvtn3,(1,2,3,0))\n",
    "amtem   = np.transpose(amtem3,(1,2,3,0))\n",
    "amalb   = np.transpose(amalb3,(1,2,3,0))\n",
    "\n",
    "\n",
    "print(\"Y_SIC.shape:\", Y_SIC.shape)\n",
    "print(\"ysic.shape:\", ysic.shape)\n",
    "print(\"msic.shape:\", msic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px, py, nyr, npatch = ysic.shape\n",
    "\n",
    "aysic_2d = aysic.reshape((px*py, nyr*npatch))\n",
    "amsic_2d = amsic.reshape((px*py, nyr*npatch))\n",
    "mthk_2d  =  mthk.reshape((px*py, nyr*npatch))\n",
    "mvtn_2d  =  mvtn.reshape((px*py, nyr*npatch))\n",
    "malb_2d  =  malb.reshape((px*py, nyr*npatch))\n",
    "mtem_2d  =  mtem.reshape((px*py, nyr*npatch))\n",
    "\n",
    "\n",
    "print(\"aysic_2d.shape:\", aysic_2d.shape)\n",
    "print(\"amsic_2d.shape:\", amsic_2d.shape)\n",
    "print(\"mthk_2d.shape :\", mthk_2d.shape)\n",
    "print(\"mvtn_2d.shape :\", mvtn_2d.shape)\n",
    "print(\"malb_2d.shape :\", malb_2d.shape)\n",
    "print(\"mtem_2d.shape :\", mtem_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "naysic_2d = scaler.fit_transform(aysic_2d)\n",
    "namsic_2d = scaler.fit_transform(amsic_2d)\n",
    "nmthk_2d  = scaler.fit_transform(mthk_2d)\n",
    "nmvtn_2d  = scaler.fit_transform(mvtn_2d)\n",
    "nmalb_2d  = scaler.fit_transform(malb_2d)\n",
    "nmtem_2d  = scaler.fit_transform(mtem_2d)\n",
    "nysic     =  ysic.reshape((px, py, nyr*npatch))/100\n",
    "nmsic     =  msic.reshape((px, py, nyr*npatch))/100\n",
    "\n",
    "print(\"naysic_2d.shape:\", naysic_2d.shape)\n",
    "print(\"namsic_2d.shape:\", namsic_2d.shape)\n",
    "print(\"nmthk_2d.shape :\", nmthk_2d.shape)\n",
    "print(\"nmvtn_2d.shape :\", nmvtn_2d.shape)\n",
    "print(\"nmalb_2d.shape :\", nmalb_2d.shape)\n",
    "print(\"nmtem_2d.shape :\", nmtem_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SIC_Center = Y_SIC[cx,cy,:,:].reshape((nyr*npatch))\n",
    "\n",
    "naysic = naysic_2d.reshape((px, py, nyr*npatch))\n",
    "namsic = namsic_2d.reshape((px, py, nyr*npatch))\n",
    "nmthk  =  nmthk_2d.reshape((px, py, nyr*npatch))\n",
    "nmvtn  =  nmvtn_2d.reshape((px, py, nyr*npatch))\n",
    "nmalb  =  nmalb_2d.reshape((px, py, nyr*npatch))\n",
    "nmtem  =  nmtem_2d.reshape((px, py, nyr*npatch))\n",
    "\n",
    "print(\"Y_SIC_Center.shape:\", Y_SIC_Center.shape)\n",
    "\n",
    "print(\"nysic.shape: \",  nysic.shape)\n",
    "print(\"nmsic.shape: \",  nmsic.shape)\n",
    "print(\"naysic.shape:\", naysic.shape)\n",
    "print(\"namsic.shape:\", namsic.shape)\n",
    "print(\"nmthk.shape: \",  nmthk.shape)\n",
    "print(\"nmvtn.shape: \",  nmthk.shape)\n",
    "print(\"nmalb.shape: \",  nmalb.shape)\n",
    "print(\"nmtem.shape: \",  nmtem.shape)\n",
    "\n",
    "print(\"nysic.range:  \",nysic.min(), nysic.max())\n",
    "print(\"nmsic.range:  \",nmsic.min(), nmsic.max())\n",
    "print(\"naysic.range: \",naysic.min(), naysic.max())\n",
    "print(\"namsic.range: \",namsic.min(), namsic.max())\n",
    "print(\"nmthk.range:  \",nmthk.min(), nmthk.max())\n",
    "print(\"nmvtn.range:  \",nmthk.min(), nmthk.max())\n",
    "print(\"nmalb.range:  \",nmalb.min(), nmalb.max())\n",
    "print(\"nmtem.range:  \",nmtem.min(), nmtem.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the prediction target of SIC\n",
    "plt.plot(Y_SIC_Center[85000:86000])\n",
    "plt.title(\"Samples of Target SIC\")\n",
    "print(\"size of Y_SIC_Center: \",Y_SIC_Center.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the standardized data and reshape\n",
    "X1 = np.stack((nysic,nmsic,naysic,namsic,nmthk,nmvtn,nmalb,nmtem))\n",
    "print(\"X1.shape:\", X1.shape)\n",
    "X  = np.transpose(X1)\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (first 90%) and testing (last 10%)\n",
    "train_num = int(ptrain*nyr*npatch)\n",
    "\n",
    "train_X = X[:train_num,:,:,:]\n",
    "test_X  = X[train_num:,:,:,:]\n",
    "train_Y = Y_SIC_Center[:train_num]\n",
    "test_Y  = Y_SIC_Center[train_num:]\n",
    "\n",
    "print(\"train_X.shape: \",  train_X.shape)\n",
    "print(\"train_Y.shape: \",  train_Y.shape)\n",
    "print(\"test_X.shape:  \",  test_X.shape)\n",
    "print(\"test_Y.shape:  \",  test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-layer CNN model with LeakyReLU as activation function and 0.25 Dropout rate \n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(5, 5),activation='relu',input_shape=(11,11,8),padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((5, 5),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), activation='relu',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(3, 3),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the training data (first 90%)\n",
    "XTraining, XValidation, YTraining, YValidation = train_test_split(train_X,train_Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training with 100 epochs\n",
    "model_train = model.fit(XTraining,YTraining, batch_size=batch_size,epochs=epochs,verbose=2,validation_data=(XValidation,YValidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(h5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['accuracy']\n",
    "val_accuracy = model_train.history['val_accuracy']\n",
    "mse = model_train.history['mse']\n",
    "val_mse = model_train.history['val_mse']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(pg_train, dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction with test data (last 10%)\n",
    "predicted_SIC = model.predict(test_X)\n",
    "predicted_SIC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the prediction target of SIC\n",
    "plt.subplot(121)\n",
    "plt.plot(test_Y[:500], 'b', label='Target SIC')\n",
    "plt.plot(predicted_SIC[:500,0], 'r', label='Predicted SIC')\n",
    "plt.title(\"Target vs. Predicted SIC\")\n",
    "plt.legend(loc='lower left')\n",
    "# These are the prediction target of SIC\n",
    "plt.subplot(122)\n",
    "plt.plot(predicted_SIC[:500,0]-test_Y[:500], 'r', label='Predicted SIC')\n",
    "plt.title(\"Predicted - Targeted SIC\")\n",
    "plt.savefig(pg_predt, dpi=150)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
